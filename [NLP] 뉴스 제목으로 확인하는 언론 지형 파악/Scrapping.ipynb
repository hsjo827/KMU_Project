{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import html\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from kiwipiepy import Kiwi\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import torch.nn.functional as F\n",
    "from kiwipiepy.utils import Stopwords\n",
    "from selenium.webdriver.common.by import By\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = ''\n",
    "client_secret = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://openapi.naver.com/v1/search/news.json' #네이버 뉴스 검색 결과 요청\n",
    "sources = ['오마이뉴스','한겨레','경향신문','조선일보','동아일보','중앙일보','연합뉴스','매일경제','머니투데이'] #언론사\n",
    "query_base = '해병대' #base 키워드\n",
    "n_display = 100 #검색 결과로 표시될 뉴스 기사의 수\n",
    "sort = 'sim' #검색결과 정렬기준(정확도)\n",
    "max_results = 1000\n",
    "\n",
    "def fetch_news(source):\n",
    "    total_results = []  \n",
    "    current_start = 1  \n",
    "    query = f\"{source} {query_base}\"  \n",
    "    encQuery = urllib.parse.quote(query)\n",
    "\n",
    "    # 반복 실행\n",
    "    while current_start <= max_results:\n",
    "    \n",
    "        url = f'{base_url}?query={encQuery}&display={n_display}&start={current_start}&sort={sort}'\n",
    "\n",
    "        my_request = urllib.request.Request(url)\n",
    "        my_request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "        my_request.add_header(\"X-Naver-Client-Secret\",client_secret) \n",
    "\n",
    "        try:\n",
    "            # API 요청 및 응답\n",
    "            with urllib.request.urlopen(my_request) as response:\n",
    "                response_body = response.read()\n",
    "            \n",
    "                # JSON 파싱\n",
    "                data = json.loads(response_body.decode('utf-8'))\n",
    "                total_results.extend(data['items'])  # 결과 저장\n",
    "                current_start += n_display  # 시작 위치 업데이트\n",
    "            \n",
    "        except urllib.error.HTTPError as e:\n",
    "            print(f\"HTTP Error: {e.code}\")\n",
    "            break  # HTTP 에러 발생 시 중단\n",
    "\n",
    "        time.sleep(1)  # 서버 부하 방지를 위한 지연\n",
    "\n",
    "    return total_results\n",
    "\n",
    "# 결과 확인\n",
    "source_results = {}\n",
    "for source in sources:\n",
    "    articles = fetch_news(source)\n",
    "    source_results[source] = articles\n",
    "    print(f\"Total articles retrieved for {source}: {len(articles)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 뉴스 link(n.news.naver.com)가 있는 뉴스에 대해서만 link얻기\n",
    "\n",
    "naver_news = {}  \n",
    "\n",
    "for source, articles in source_results.items():\n",
    "    naver_news[source] = []  \n",
    "    for article in articles:\n",
    "        link = html.unescape(article['link']).replace('\\\\', '') \n",
    "        pubdate = article['pubDate']\n",
    "        if 'n.news.naver.com' in link: \n",
    "            naver_news[source].append({\n",
    "                'link': link,\n",
    "                'pubDate': pubdate\n",
    "            })\n",
    "\n",
    "naver_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오마이뉴스(47),한겨레(28), 경향신문(32),조선일보(23),동아일보(20),중앙일보(25),뉴시스(3),뉴스1(421),연합뉴스(1)\n",
    "\n",
    "source_substrings = {\n",
    "    '오마이뉴스': 'https://n.news.naver.com/mnews/article/047',  \n",
    "    '한겨레': 'https://n.news.naver.com/mnews/article/028',        \n",
    "    '경향신문': 'https://n.news.naver.com/mnews/article/032',     \n",
    "    '조선일보': 'https://n.news.naver.com/mnews/article/023',       \n",
    "    '동아일보': 'https://n.news.naver.com/mnews/article/020',      \n",
    "    '중앙일보': 'https://n.news.naver.com/mnews/article/025',\n",
    "    '연합뉴스': 'https://n.news.naver.com/mnews/article/001',\n",
    "    '매일경제': 'https://n.news.naver.com/mnews/article/009',\n",
    "    '머니투데이': 'https://n.news.naver.com/mnews/article/008'\n",
    "}       \n",
    "\n",
    "\n",
    "filtered_links = {}\n",
    "for source, substring in source_substrings.items():\n",
    "    source_articles = naver_news.get(source, [])  \n",
    "    filtered_links[source] = [article['link'] for article in source_articles if substring in article['link']]\n",
    "\n",
    "for source, links in filtered_links.items():\n",
    "    print(f\"Filtered links for {source}:\")\n",
    "    for link in links:\n",
    "        print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {key: len(value) for key, value in filtered_links.items()}\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selenium의 webdriver에서 웹페이지 열기\n",
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 페이지 로드를 위해 기다리는 시간\n",
    "driver.implicitly_wait(1)\n",
    "\n",
    "# 제목 수집하기\n",
    "articles_titles = {}\n",
    "\n",
    "for source, links in filtered_links.items():\n",
    "    articles_titles[source] = []\n",
    "    for link in links:\n",
    "        driver.get(link)\n",
    "        time.sleep(1) \n",
    "        try:\n",
    "            title_element = driver.find_elements(By.CLASS_NAME, 'media_end_head_title')\n",
    "            if title_element:\n",
    "                title = title_element[0].text\n",
    "                articles_titles[source].append({'title': title, 'link': link})\n",
    "            else: \n",
    "                print(f\"No title found for link: {link}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract title from {link}: {e}\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for source, articles in articles_titles.items():\n",
    "    for article in articles:\n",
    "        data.append({\n",
    "            'Source': source,\n",
    "            'Link': article['link'],\n",
    "            'Title': article['title']\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('news_articles_해병대.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
